This chapter is contributed by Ch. Q. Lauter.


\section{Overview of the algorithm}
The exponential function allows for additive argument reduction with
multiplicative reconstruction: $e^{a + b} = e^a \cdot e^b$. In
particular, the following equation is useful in developing an
argument reduction:
$$e^x = e^{E \cdot \ln\left(2\right) + z} = \left(e^{\ln\left( 2
\right)}\right)^E \cdot e^z = 2^E \cdot e^z$$ Here, $E$ can be
considered to be a signed integer, $E \in \Z$ and $z$ to be a reduced
argument such that $\left \vert z \right \vert <
\ln\left(2\right)$. One remarks that the use of such an argument
reduction implies a multiplication with a transcendental constant,
$\ln\left( 2 \right)$.  This means that the reduced argument will not
be exact. The corresponding error bound will be given in section
\ref{sec:expargred}.

A reduced argument obtained by the reduction shown above is generally
still to great for polynomial approximation. By use of tabulation
methods, the following argument reduction can be employed and yields
to smaller reduced arguments.
\begin{eqnarray*}
k & = & \left \lfloor x \cdot \frac{2^l}{\ln\left(2 \right)} \right \rceil \\
\hat{r} & = & x - k \cdot \frac{\ln\left( 2 \right)}{2^l} \\
k & = & 2^l \cdot M + 2^{w_1} \cdot i_2 + i_1 
\end{eqnarray*}
where $\hat{r}$ is the reduced argument, $k, M \in \N$ are intermediate
integers, and $w_1, w_2 \in \N$, $l = w_1 + w_2$, are the widths of
the indices to the two tables. The corresponding reconstruction phase
is
$$e^x = 2^M \cdot 2^{\frac{i_2}{2^{w_1}}} \cdot 2^{\frac{i_1}{2^l}}
\cdot e^{\hat{r}} = 2^M \cdot t_1 \cdot t_2 \cdot e^{\hat{r}}$$ with the table values $t_1 =
2^{\frac{i_2}{2^{w_1}}}$ and $t_2 = 2^{\frac{i_1}{2^l}}$. The argument
reduction ensures that $\left \vert \hat{r} \right \vert \leq
\frac{\ln\left( 2 \right)}{2^l} < 2^{-l}$. This magnitude is small enough for 
allowing for polynomial approximation.

In the case of the given algorithm, we use $l = 12$ and $w_1 = w_2 = 6$.

The subtraction $\hat{r} = x - k \cdot \round \left(\frac{\ln\left( 2
\right)}{2^l}\right)$ can be implemented exactly but leads to
catastrophic cancellation that amplifies the absolute error of the
potentially exact multiplication of $k$ by the approximated
$\frac{\ln\left( 2 \right)}{2^l}$. Is is nevertheless not of such an
issue, as will be shown in section \ref{sec:expaccuracy}.                  % ATTENTION: CHANGER EVTL LA MARQUE

\section{Special case handling}\label{sec:expspecial}
The exponential function $e^x$, which is monotone increasing, produces
results that are representable in a floating point format for
arguments $$x \in \left[ \mbox{\small \it underflowBound};
\mbox{\small \it overflowBound} \right]$$ Herein the following values
are observed for double precision: $$\mbox{\small \it underflowBound}
= \round \left( \ln\left(2^{-1075} \right) \right) \approx -745.13$$
and $$\mbox{\small \it overflowBound} = \round \left(
\ln\left(2^{1024} \cdot \left( 1 - 2^{-53} \right) \right) \right)
\approx 709.78$$ Its double precision result is gradually underflowed
in the argument domain $$x \in \left[\mbox{\small \it underflowBound};
\mbox{\small \it denormBound} \right]$$ where
$$\mbox{\small \it denormBound} = \round\left( \ln\left( 2^{-1022}
\right) \right) \approx -708.40$$ for double precision.  No special
case can therefore occur for arguments $x$ such that $$\left \vert x
\right \vert \leq \min \left( \left \vert \mbox{\small \it
underflowBound} \right \vert, \left \vert \mbox{\small \it
overflowBound} \right \vert, \left \vert \mbox{\small \it denormBound}
\right \vert \right) \approx 708.40$$ This provides us a very
efficient filter for the greatest part of the definition domain.
Since also some arguments are filtered out that actually do not
represent a special case, additional tests are made in the body of the
main special handling sequence launched by the filter. Particular cases like
$x=\pm \infty$, $x = \nan$ are handled as follows:
\begin{itemize}
\item The result for $x = \nan$ is $\nan$.
\item The result for $x = + \infty$ is $+ \infty$.
\item The result for $x = - \infty$ is $0$, even in round-upwards mode.
\end{itemize}
If the result is clearly underflowed, $0$ is returned with the inexact
flag set for round-to-nearest and round-downwards, $0^+$ is returned
for round-upwards.

The ordering of double precision numbers is compatible with the
integer ordering of the signed 64 bit integers the floating point
numbers can be read in memory as. Further the ordering on numbers is
equal to the lexicographic ordering of its digits. So if the higher
order word of $\left \vert x \right \vert$ is less than the higher
order word of $\mbox{\small \it overUnderDenormBound} = \min \left(
\left \vert \mbox{\small \it underflowBound} \right \vert, \left \vert
\mbox{\small \it overflowBound} \right \vert, \left \vert \mbox{\small
\it denormBound} \right \vert \right)$, no underflow, gradual
underflow or overflow can occur. In the other cases, special handling
in the reconstruction step may be necessary. A flag
\texttt{mightBeDenorm} is set for possible subnormals. Cases where
intermediate results are not representable because of overflow but
where the final result is representable can be overcome by replacing
the corresponding floating point multiplication by an integer
manipulation. This will be shown below.

Since $e^{x} = 1 + x + \Ord\left( x^2 \right)$ for small $\left
\vert x \right \vert$, underflowed arguments $x$ ($\left \vert x \right
\vert \leq 2^{-1022}$) can be handled as follows:
\begin{itemize}
\item In round-to-nearest mode, $1$ can be returned since $\round
\left( 1 + x \right) = 1$ for $\left \vert x \right \vert \leq
2^{-54}$.
\item In round-upwards mode, $1$ must be returned for $x = 0$. For $x
< 0$, $1$ can be returned, too, because $\roundup \left( 1 - \left
\vert x \right \vert \right) = 1$.  If $x > 0$, $1^+$ must be
returned.
\item Round-downwards mode is analogous to round-upwards mode, but the signs 
are inverted. 
\item Round-towards-zero mode is equivalent to round-downwards mode since 
$e^x > 0 \mbox{~~} \forall x \in \R$.
\end{itemize}

The following sequence realizes the special case handling for
round-to-nearest. The sequences for the other rounding modes are
straightforward and will not be shown here. The constants\\
\texttt{OVRUDRFLWSMPLBOUND}, \texttt{OVRFLWBOUND} and
\texttt{DENORMBOUND} are computed by the corresponding Maple script
that realizes the equations given above.
\begin{lstlisting}[caption={Handling special cases},firstnumber=1]
/* Special cases tests */
xIntHi = xdb.i[HI];
mightBeDenorm = 0;
/* Test if argument is a denormal or zero */
if ((xIntHi & 0x7ff00000) == 0) {
  /* We are in the RN case, return 1.0 in all cases */
  return 1.0;
}

/* Test if argument is greater than approx. 709 in magnitude */
if ((xIntHi & 0x7fffffff) >= OVRUDRFLWSMPLBOUND) {
  /* If we are here, the result might be overflowed, underflowed, inf, or NaN */

  /* Test if +/- Inf or NaN */
  if ((xIntHi & 0x7fffffff) >= 0x7ff00000) {
    /* Either NaN or Inf in this case since exponent is maximal */

    /* Test if NaN: mantissa is not 0 */
    if (((xIntHi & 0x000fffff) | xdb.i[LO]) != 0) {
	/* x = NaN, return NaN */
	return x + x;
    } else {
	/* +/- Inf */

	/* Test sign */
	if ((xIntHi & 0x80000000)==0) 
	  /* x = +Inf, return +Inf */
	  return x;
	else
	  /* x = -Inf, return 0 */
	  return 0;
    } /* End which in NaN, Inf */
  } /* End NaN or Inf ? */
  
  /* If we are here, we might be overflowed, denormalized or underflowed in the result 
     but there is no special case (NaN, Inf) left */

  /* Test if actually overflowed */
  if (x > OVRFLWBOUND) {
    /* We are actually overflowed in the result */
    return LARGEST * LARGEST;
  }

  /* Test if surely underflowed */
  if (x <= UNDERFLWBOUND) {
    /* We are actually sure to be underflowed and not denormalized any more 
	 So we return 0 and raise the inexact flag */
    return SMALLEST * SMALLEST;
  }
     
  /* Test if possibly denormalized */
  if (x <= DENORMBOUND) {
    /* We know now that we are not sure to be normalized in the result
	 We just set an internal flag for a further test 
    */
    mightBeDenorm = 1;
  }
} /* End might be a special case */
\end{lstlisting}
\section{Argument reduction}\label{sec:expargred}
Mathematically, the argument reduction used for quick and accurate phase is the same.
The reduced argument is nevertheless different for the both phases because the
reduction is inexact. It is therefore implemented in two or three phases:

First, $k$ corresponding to $\left \lfloor x \cdot
\frac{2^{12}}{\ln\left(2 \right)} \right \rceil$ is computed in both
integer and floating point (double) representation. Herein
$\frac{2^{12}}{\ln\left(2 \right)}$ is represented in double precision
and the multiplication by $x$ is performed in double precision,
too. Then the nearest integer $k$ to the number obtained is
computed. This computational problem is principally subject to the
Table Maker's Dilemma: $x \cdot \frac{2^{12}}{\ln\left(2 \right)}$ is
transcendental for all $x \not = \ln\left(2 \right)$ and the
to-nearest-integer operation is equivalent to a rounding to the
nearest. It is not possible to guarantee that the computed $k$ is
really the integer nearest to $x \cdot \frac{2^{12}}{\ln\left(2
\right)}$. Nevertheless, this is not a problem. The following argument
reduction steps, as $\hat{r} = x - k \cdot
\frac{\ln\left(2\right)}{2^{12}}$, and the reconstruction are
mathematically correct for any $k$. So computing the wrong $k$ only
leads to a slight enlargement of the interval of the reduced argument
$\hat{r}$, as one can see with the following argument:

The function's argument's value $x$ is bounded in magnitude by
$2^{10}$. So, $x \cdot \frac{2^{12}}{\ln\left(2 \right)}$ is bounded
in magnitude by $2^{22}$. Since the accuracy of the value
$xMultLog2InvMult2L = \round \left( x \cdot \round \left(
\frac{2^{12}}{\ln\left(2 \right)} \right) \right)$ with respect to the
exact value $x \cdot \frac{2^{12}}{\ln\left(2 \right)}$ is at least
$51$ bits, an error is made not earlier than at the $19$th bit
following the integer-fractional point. Thus
$$\left \vert \frac{k - x \cdot \frac{2^{12}}{\ln\left(2
      \right)}}{x \cdot \frac{2^{12}}{\ln\left(2 \right)}} \right
\vert \leq \frac{1}{2} + 2^{-19}$$ Therefore $\hat{r}^\prime$ is
actually bounded by $\left \vert \hat{r}^\prime \right \vert \leq
\frac{\ln\left( 2 \right)}{2^{12}} \cdot \left( \frac{1}{2} + 2^{-19}
\right)$ instead of $\left \vert \hat{r} \right \vert \leq
\frac{\ln\left( 2 \right)}{2^{12}} \cdot \frac{1}{2}$. This difference
can be taken into account in the error computation, and we may safely
assume that its effects will be negligible.

Note further that $k$ is computed exactly ($k = 0$) for $\left \vert x
\right \vert \leq 2^{-14}$ because no Table Maker's Dilemma can no
longer occur.

This first step is performed by the following code sequence:
\begin{lstlisting}[caption={Argument reduction - first step},firstnumber=1]
xMultLog2InvMult2L = x * log2InvMult2L;
shiftedXMult = xMultLog2InvMult2L + shiftConst;
kd = shiftedXMult - shiftConst;
shiftedXMultdb.d = shiftedXMult;
k = shiftedXMultdb.i[LO];
\end{lstlisting}
Here, \texttt{k} and \texttt{kd} represent $k$ in integer and floating
point (double) format. The technique for computing $\left \lfloor z
\right \rceil$ out of $z$ is explained in section
\ref{sec:double2int}, page \pageref{sec:double2int}.

In the second step of the argument reduction, an arithmetical
approximation to $\hat{r} = x - k \cdot \frac{\ln\left( 2
\right)}{2^{12}}$, $r_\hi + r_\mi = \hat{r} + \delta_{\mbox{\tiny
argred}}$, is computed using a double-double approximation to
$\frac{\ln\left( 2 \right)}{2^{12}}$ and double-double precision for
computations. We will consider its absolute error $\delta_{\mbox{\tiny
argredquick}} = r_\hi + r_\mi - \hat{r}$ and the resulting relative
error on the exponential function $\epsilon_{\mbox{\tiny argredquick}}
= \frac{e^{\hat{r} + \delta} - e^{\hat{r}}}{e^{\hat{r}}}$ below.

This argument reduction step is implemented as follows:
\begin{lstlisting}[caption={Argument reduction - second step},firstnumber=1]
Mul12(&s1,&s2,msLog2Div2Lh,kd);
s3 = kd * msLog2Div2Lm;
s4 = s2 + s3; 
s5 = x + s1;
Add12Cond(rh,rm,s5,s4);
\end{lstlisting}
Here, \texttt{msLog2Div2Lh} and \texttt{msLog2Div2Lm} are a
double-double representing $-\frac{\ln\left( 2 \right)}{2^{12}}$ with
an relative error $\left \vert \epsilon_{\mbox{\tiny logconstquick}}
\right \vert = \left \vert \frac{msLog2Div2L_\hi + msLog2Div2L_\mi +
2^{-12} \cdot \ln\left( 2 \right)}{-2^{-12} \cdot \ln\left( 2 \right)}
\right \vert \leq 2^{-109}$. Further, $\left \vert msLog2Div2L_\hi
\right \vert \leq 2^{-54} \cdot \left \vert msLog2Div2L_\mi \right
\vert$.

Let us now show first a bound on the absolute round-off error of the
given sequence.  We know that the multiplication $s_1 + s_2 = kd \cdot
msLog2Div2h$ and the final addition $r_\hi + r_\mi = s_5 + s_4$ are
exact. Further, the addition $s_5 = x \oplus s_1$ is exact as per Sterbenz' lemma.
In fact, since 
$$\left \vert x - \left \lfloor x \cdot
\frac{2^{12}}{\ln\left(2\right)} \right \rceil \cdot
\frac{\ln\left(2\right)}{2^{12}} \right \vert \leq 2^{-12}$$ and
$$s_1 = - \left \lfloor x \cdot \frac{2^{12}}{\ln\left(2\right)}
\right \rceil \cdot \frac{\ln\left(2\right)}{2^{12}} \cdot \left( 1 + \epsilon^\prime \right)$$
with $\left \vert \epsilon^\prime \right \vert \leq 2^{-50}$, it is trivial to see that
$$\frac{1}{2} \cdot \left \vert s_1 \right \vert \leq \left \vert x
\right \vert \leq 2 \cdot \left \vert s_1 \right \vert$$ In addition,
$s_1$ and $x$ are clearly of opposed sign. So, noting
$$s_3 = k \cdot msLog2Div2L_\mi \cdot \left( 1 + \epsilon_1 \right)$$ and
$$s_4 = \left( s_2 + s_3 \right) \cdot \left( 1 + \epsilon_2 \right)$$
with $\left \vert \epsilon_1 \right \vert \leq 2^{-53}$ and $\left
\vert \epsilon_2 \right \vert \leq 2^{-53}$, we get
$$r_\hi + r_\mi = x + k \cdot \left( msLog2Div2L_\hi + msLog2Div2L_\mi \right) + \delta^\prime$$
with 
$$\left \vert \delta^\prime \right \vert \leq \left \vert \epsilon_1 \right
\vert \cdot \left \vert k \cdot msLog2Div2L_\mi \right \vert + \left
\vert \epsilon_2 \right \vert \cdot \left \vert s_2 + s_3 \right
\vert$$
We have
$$\left \vert s_2 \right \vert \leq 2^{-53} \cdot \left \vert s_1
\right \vert \leq 2^{-53} \cdot \left \vert \round \left( k \cdot
msLog2Div2L_\hi \right) \right \vert \leq 2^{-52} \cdot \left \vert k
\cdot msLog2Div2L_\hi \right \vert$$
and further
$$\left \vert s_3 \right \vert \leq \left \vert k \cdot msLog2Div2L_\mi \left( 1 + \epsilon_1 \right) \right \vert
\leq \left \vert k \cdot msLog2Div2L_\mi \right \vert + \left \vert \epsilon_1 \right \vert \cdot
\left \vert k \cdot msLog2Div2L_\mi \right \vert$$
So one can easily check that 
$$\left \vert \delta^\prime \right \vert \leq 2^{-104} \cdot \left
\vert k \cdot msLog2Div2Lh \right \vert$$ In consequence using the
fact that $\left \vert msLog2Div2L_\hi \right \vert = \left \vert \round
\left( \frac{\ln\left( 2 \right)}{2^{12}} \right) \right \vert \leq 2
\cdot \left \vert \frac{\ln\left( 2 \right)}{2^{12}} \right \vert$ and
the bound for $k$, one obtains
$$\left \vert \delta^\prime \right \vert \leq \left \vert \left( x
\cdot \frac{2^{12}}{\ln\left( 2 \right)} + \frac{1}{2} + 2^{-19}
\right) \cdot \frac{\ln\left( 2 \right)}{2^{12}} \right \vert$$ Since
$\left \vert x \right \vert \leq 746$ after filtering out the special
cases, we obtain $\left \vert \delta^\prime \right \vert \leq 2^{-103}
\cdot 2^{10} = 2^{-93}$.  

To this round-off error adds the
approximation error comitted by rounding $\frac{\ln\left( 2
\right)}{2^{12}}$ to a double-double.
We can note 
$$r_\hi + r_\mi = x - k \cdot \frac{\ln\left( 2 \right)}{2^{12}} \cdot
\left( 1 + \epsilon_{\mbox{\tiny logconstquick}} \right) +
\delta^\prime$$
This gives us 
$$r_\hi + r_\mi = \hat{r} + \delta$$ with $\left \vert \delta \right
\vert \leq \left \vert k \cdot \frac{\ln\left( 2 \right)}{2^{12}}
\cdot \epsilon_{\mbox{\tiny logconstquick}} \right \vert + \left \vert
\delta^\prime \right \vert$. One can easily check that one obtains
thus finally $\left \vert \delta \right \vert \leq 2^{-92}$.

This absolute error $\delta$ in the reduced argument $\hat{r}$
translates to a relative error $\epsilon_{\mbox{\tiny argredquick}}$ in the function $e^{\hat{r}}$ as
follows:
\begin{eqnarray*}
e^r & = & e^{\hat{r} + \delta} \\
& = & e^{\hat{r}} \cdot e^{\delta} \\
& = & e^{\hat{r}} \cdot \sum\limits_{i=0}^{\infty} \frac{1}{i!} \cdot \delta^i \\
& = & e^{\hat{r}} \cdot \left( 1 + \sum\limits_{i=1}^{\infty} \frac{1}{i!} \cdot \delta^i \right) \\
& = & e^{\hat{r}} \cdot \left( 1 + \epsilon_{\mbox{\tiny argredquick}} \right)
\end{eqnarray*}
with $\epsilon_{\mbox{\tiny argredquick}} = \sum\limits_{i=1}^{\infty} \frac{1}{i!} \cdot \delta^i =
\delta \cdot \sum\limits_{i=0}^{\infty} \frac{1}{\left(i + 1 \right)!}
\cdot \delta^i$.
Since $\left \vert \delta \right \vert < \frac{1}{2}$, we get 
$$\forall i \geq 0 \mbox{ . } \left \vert \frac{1}{\left( i + 1
\right)!} \cdot \delta^i \right \vert \leq \left( \frac{1}{2}
\right)^i$$ In consequence, $\sum\limits_{i=0}^{\infty}
\frac{1}{\left(i + 1 \right)!}  \cdot \delta^i \leq
\sum\limits_{i=0}^{\infty} \left( \frac{1}{2} \right)^i = 2$.  

Thus we get $\left \vert \epsilon_{\mbox{\tiny argredquick}} \right
\vert \leq 2 \cdot \left \vert \delta \right \vert \leq 2^{-91}$.

Still in the second step of the argument reduction, the values $M$,
$i_1$ and $i_2$ are computed exactly in integer computation as
follows:
\begin{lstlisting}[caption={Argument reduction - second step (cont'd)},firstnumber=1]
M = k >> L;
index1 = k & INDEXMASK1;
index2 = (k & INDEXMASK2) >> LHALF;
\end{lstlisting}
Here \texttt{L} is equal to $12$ and \texttt{LHALF} is equal to
$6$. The values \texttt{INDEXMASK1} and \texttt{INDEXMASK2} are masks
to the lowest 6 bits and respectively to bits 6 through 15 of an 32
bit word.

If ever the accurate phase must be launched, a third argument
reduction phase is performed.  It computes a triple-double $r_\hi +
r_\mi + r_\lo = \hat{r} + \delta$ such that the resulting relative
error on the exponential function $\epsilon_{\mbox{\tiny
argredaccurate}} = \frac{e^{\hat{r} + \delta} -
e^{\hat{r}}}{e^{\hat{r}}}$ is bounded by $\left \vert
\epsilon_{\mbox{\tiny argredaccurate}} \right \vert \leq 2^{-140}$ as
will be shown below. This step uses a triple-double approximation to
$\frac{\ln\left( 2 \right)}{2^{12}}$ with a relative error $$\left
\vert \epsilon_{\mbox{\tiny logconstaccurate}} \right \vert = \left
\vert \frac{msLog2Div2L_\hi + msLog2Div2L_\mi + msLog2Div2L_\lo +
2^{-12} \cdot \ln\left( 2 \right)}{-2^{-12} \cdot \ln\left( 2 \right)}
\right \vert \leq 2^{-163}$$ It is implemented as follows:
\begin{lstlisting}[caption={Argument reduction - third step},firstnumber=1]
Mul133(&msLog2Div2LMultKh,&msLog2Div2LMultKm,&msLog2Div2LMultKl,kd,msLog2Div2Lh,msLog2Div2Lm,msLog2Div2Ll);
t1 = x + msLog2Div2LMultKh;
Add12Cond(rh,t2,t1,msLog2Div2LMultKm);
Add12Cond(rm,rl,t2,msLog2Div2LMultKl);
\end{lstlisting}
The values for $k$, $M$, $i_1$ and $i_2$ that have been exactly
computed already at the second argument reduction step can of course
be reused.

All operation but the first \texttt{Mul133} operator are exact: the
last two by their general properties, the addition $t_1 = x \oplus
msLog2Div2LMultK_\hi$ as per Sterbenz' lemma analogously as in the
second argument reduction step. So one can note
$$r_\hi + r_\mi + r_\lo = x - k \cdot \left( msLog2Div2L_\hi +
msLog2Div2L_\mi + msLog2Div2L_\lo \right) \cdot \left( 1 + \epsilon_1
\right)$$ where $\epsilon_1$ is the relative error bound of the
\texttt{Mul133} operator, for instance $\left \vert \epsilon_1 \right
\vert \leq 2^{-153}$. Integrating also the rounding error in the constant, we
get 
$$r_\hi + r_\mi + r_\lo = x - k \cdot \frac{\ln\left( 2
\right)}{2^{12}} + \delta$$ with $\left \vert \delta \right \vert \leq
\left \vert k \cdot \frac{\ln\left( 2 \right)}{2^{12}} \right \vert
\cdot \left( 2^{-163} + 2^{-153} \right) \leq 2^{-152} \cdot \left
\vert k \cdot \frac{\ln\left( 2 \right)}{2^{12}} \right \vert \leq
2^{-141}$.  One checks the previous upper bounds by using analogous
arguments as the ones given for the second argument reduction step.
Once again, this absolute error $\delta$ translates to a relative
error $\epsilon_{\mbox{\tiny argredaccurate}} = \frac{e^{\hat{r} +
\delta} - e^{\hat{r}}}{e^{\hat{r}}}$ in a similar way as mentioned
above. We get $$\left \vert \epsilon_{\mbox{\tiny argredaccurate}}
\right \vert \leq 2^{-140}$$ which is the bound to prove.

Let us still remark that argument reduction is exact for arguments $x$
such that $\left \vert x \right \vert \leq \frac{\ln\left( 2
\right)}{2^{13}} < 2^{-13}$. In fact, in this case, $k = 0$ which
implies that all multiplications of $k$ by the constants for
$\frac{\ln\left( 2 \right)}{2^{12}}$ are exact. 

According to their uses either in quick or accurate phase, the table
values $t_1 = e^{\frac{i_1}{2^{12}}}$ and $t_2 =
e^{\frac{i_1}{2^{12}}}$ for $i_1, i_2 \in \left \lbrace 0 \dots 63
\right \rbrace$ are read as a double-double or as a triple-double. By
construction, the double-double values have a relative error
$\epsilon_{\mbox{\tiny tablequick}} = \frac{tbl_{i\hi} + tbl_{i\mi} -
t_i}{t_i}$ bounded by $\left \vert \epsilon_{\mbox{\tiny tablequick}}
\right \vert \leq 2^{-106}$.  The triple-double values with
$\epsilon_{\mbox{\tiny tableaccurate}} = \frac{tbl_{i\hi} + tbl_{i\mi}
+ tbl_{i\lo} - t_i}{t_i}$ verify $\left \vert \epsilon_{\mbox{\tiny
tableaccurate}} \right \vert \leq 2^{-159}$. For $i_1 = 0$ and $i_2 =
0$ both errors are equal to $0$, so both argument reduction and
reconstruction steps are exact for argument $x$ that verify $\left
\vert x \right \vert \leq 2^{-13}$.

\section{Polynomial approximation and reconstruction}\label{sec:exppolynomial}
In both quick and accurate phase, the reduced argument $r_\hi + r_\mi$
respectively $r_\hi + r_\mi + r_\lo$ corresponding to their
mathematical equivalent $\hat{r}$ are bounded by $\left \vert \hat{r}
\right \vert \leq \frac{\ln\left( 2 \right)}{2^{12}} \cdot \left(
2^{-1} + 2^{-19} \right) + \delta < 2^{-13}$.  After simplification by
$e^{r_\hi + r_\mi + r_\lo} = e^{r_\hi} \cdot e^{r_\mi} \cdot
e^{r_\lo}$, $e^{r_\hi} - 1$ is approximated by a polynomial of degree
4 or 7. The functions $e^{r_\mi} - 1$ and potentially $e^{r_\lo} - 1$
are both approximated linearly by $r_\mi$ or, respectively, $r_\lo$.

Concerning the approximation errors for $e^{r_\mi}$ and $e^{r_\lo}$,
one can note that $\left \vert r_\mi \right \vert \leq 2^{-52} \cdot
2^{-13} \leq 2^{-65}$ and $\left \vert r_\lo \right \vert \leq
2^{-105} \cdot 2^{-13} \leq 2^{-118}$. In consequence
$\epsilon_{\mbox{\tiny approxargmiddle}} = \frac{r_\mi - \left(
e^{r_\mi} - 1 \right)}{\left( e^{r_\mi} - 1 \right)}$ and
$\epsilon_{\mbox{\tiny approxarglower}} = \frac{r_\lo - \left(
e^{r_\lo} - 1 \right)}{\left( e^{r_\lo} - 1 \right)}$ are bounded by
$\left \vert \epsilon_{\mbox{\tiny approxargmiddle}} \right \vert \leq
2^{-66}$ and $\left \vert \epsilon_{\mbox{\tiny approxarglower}}
\right \vert \leq 2^{-119}$.

\subsection{Quick phase polynomial approximation and reconstruction}
In quick phase $e^{r_\hi} - 1$ is approximated by a polynomial
$p\left( r_\hi \right)$ of the following form
$$p\left( r_\hi \right) = r_\hi + \frac{1}{2} \cdot r_\hi^2 + c_3
\cdot r_\hi^3 + c_4 \cdot r_\hi^4$$ The coefficients $c_3$ and $c_4$
are stored in double precision, $\frac{1}{2}$ is exactly
representable. For $r_\hi$ bounded as indicated above, the relative
approximation error $\epsilon_{\mbox{\tiny approxarghighquick}} =
\frac{p\left( r_\hi \right) - e^{r_\hi} + 1}{e^{r_\hi} - 1}$ is bounded by 
$\left \vert \epsilon_{\mbox{\tiny approxarghighquick}} \right \vert \leq 2^{-62}$.

The polynomial $p\left(r_\hi \right) - r_\hi = \frac{1}{2} \cdot
r_\hi^2 + c_3 \cdot r_\hi^3 + c_4 \cdot r_\hi^4$ is evaluated in
double precision using the following scheme:
\begin{enumerate}
\item In the beginning, an approximation to $r_\hi^2$, $rhSquare$, is computed. Concurrently, 
$c_3$ is multiplied by $r_\hi$ yielding to $rhC3 = c_3 \cdot r_\hi \cdot \left( 1 + \epsilon \right)$.
\item At the first step, the squared argument $rhSquare$ is multiplied
by $\frac{1}{2}$ yielding to the approximation $rhSquareHalf$. At the
same time, it is multiplied by $rhC3$ which results in $monomialCube$
approximating now $c_3 \cdot r_\hi^3$. Still in the same moment, it is
squared once again yielding to $rhFour$ which approximates thus
$r_\hi^4$.
\item At the next dependency top, $rhFour$ is multiplied by
$c_4$. This results in $monomialFour$ -- a value corresponding to $c_4
\cdot r_\hi^4$.
\item In the next moment, $monomialCube$ and $monomialFour$ are added
together. This gives a value approximating $c_3 \cdot r_\hi^3 + c_4
\cdot r_\hi^4$.
\item Finally, $rhSquareHalf$ is added to the value obtained at the
previous step yielding to an arithmetical approximation of
$\frac{1}{2} \cdot r_\hi + c_3 \cdot r_\hi^3 + c_4 \cdot r_\hi^4$,
stored in $highPolyWithSquare$.
\end{enumerate}
This scheme does not completely exploit the possible parallelism for
purpose of not deteriorating too much the final accuracy. It is
implemented as follows:
\begin{lstlisting}[caption={Quick phase polynomial evaluation - high order terms},firstnumber=1]
rhSquare = rh * rh;
rhC3 = c3 * rh;

rhSquareHalf = 0.5 * rhSquare;
monomialCube = rhC3 * rhSquare;
rhFour = rhSquare * rhSquare;

monomialFour = c4 * rhFour;

highPoly = monomialCube + monomialFour;

highPolyWithSquare = rhSquareHalf + highPoly;
\end{lstlisting}
The following steps must still add the linear term $r_\hi$ of the
polynomial ($p\left( r_\hi \right) = r_\hi + highPolyWithSquare$) and
reconstruct the exponential as
$$e^{x} = 2^M \cdot \left( tbl_{1\hi} + tbl_{1\mi} \right) \cdot
\left( tbl_{2\hi} + tbl_{2\mi} \right) \cdot \left( 1 + r_\hi +
highPolyWithSquare \right) \cdot \left( 1 + r_\mi \right) + \delta$$
In order to allow for increasing speed by approximating different
terms, they are implemented as this:
\begin{enumerate}
\item The two table values $tbl_{1\hi} + tbl_{1\mi}$ and $tbl_{2\hi} +
tbl_{2\mi}$ are multiplied using a double-double multiplication
operator yielding to $tables_\hi + tables_\lo = \left( tbl_{1\hi} +
tbl_{1\mi} \right) \cdot \left( tbl_{2\hi} + tbl_{2\mi} \right) \cdot
\left( 1 + \epsilon \right)$.
\item The term \\
$\left( 1 + r_\hi + highPolyWithSquare \right) \cdot
\left( 1 + r_\mi \right) =$ \\ $1 + r_\hi + highPolyWithSquare + r_\mi +
r_\hi \cdot r_\mi + highPolyWithSquare \cdot r_\mi$ \\ is approximated
by neglecting the quadratic terms. First $r_\hi$ and
$highPolyWithSquare$ are added together in double precision. Their sum
is then added to $r_\hi$ in double precision, too.  This yields to the
intermediate value $t_9$. The addition with $1$ is not explicited.
\item The multiplication $\left( tables_\hi + tables_\lo \right) \cdot
\left( 1 + t_9 \right)$ is approximated by $tables_\hi + tables_\lo +
tables_\hi \cdot t_9$. The multiplication $tables_\hi \cdot t_9$ is
performed in double precision. It produces $t_{10}$.
\item The addition $tables_\hi + tables_\lo + t_{10}$ is carried out
in double-double precision. Its result $polyTbl_\hi + polyTbl_\mi$
approximates finally
$$polyTbl_\hi + polyTbl_\mi = \left( tbl_{1\hi} + tbl_{1\mi} \right)
\cdot \left( tbl_{2\hi} + tbl_{2\mi} \right) \cdot \left( 1 + p\left(
r_\hi \right) \right) \cdot \left( 1 + r_\mi \right) \cdot \left( 1 +
\epsilon \right)$$
for some relative error $\epsilon$.
\end{enumerate}
The steps explained above are implemented in the code as follows:
\begin{lstlisting}[caption={Quick phase reconstruction},firstnumber=1]
Mul22(&tablesh,&tablesl,tbl1h,tbl1m,tbl2h,tbl2m);

t8 = rm + highPolyWithSquare;
t9 = rh + t8;

t10 = tablesh * t9;

Add12(t11,t12,tablesh,t10);
t13 = t12 + tablesl;
Add12(polyTblh,polyTblm,t11,t13);
\end{lstlisting}

The final result for the exponential is $e^x \approx 2^M \cdot \left(
polyTbl_\hi + polyTbl_\mi \right)$.  On this value, a rounding test
would have to be performed. Since gradual underflow is excluded by
special case handling, the multiplication by $2^M$ is exact. In
consequence, it is possible to do the rounding test on $polyTbl_\hi +
polyTbl_\mi$ and to multiply then by $2^M$. This is the way chosen in
the given implementation. See section \ref{sec:expfinalround}, page
\pageref{sec:expfinalround}, for further details.

\subsection{Accurate phase polynomial approximation and reconstruction}
In accurate phase, $e^{r_\hi} - 1$ is approximated by a polynomial
$p\left( r_\hi \right)$ of degree $7$. It has the following form:
$$p\left( r_\hi \right) = r_\hi + \frac{1}{2} \cdot r_\hi^2 + r_\hi^3
\cdot \left( \left( c_{3\hi} + c_{3\lo} \right) + r_\hi \cdot \left(
\left( c_{4\hi} + c_{4\lo} \right) + r_\hi \cdot \left( c_5 + r_\hi
\cdot \left( c_6 + r_\hi \cdot c_7 \right) \right) \right) \right)$$
Coefficients $c_{3\hi} + c_{3\lo}$ and $c_{4\hi} + c_{4\lo}$ are
stored as double-double numbers, coefficients $c_5$ through $c_7$ are
stored in double precision.

For $r_\hi$ bounded by $\left \vert r_\hi \right \vert \leq 2^{-13}$,
the relative approximation error $\epsilon_{\mbox{\tiny
approxarghighaccu}} = \frac{p\left( r_\hi \right) - e^{r_\hi} +
1}{e^{r_\hi} - 1}$ is bounded by $\left \vert \epsilon_{\mbox{\tiny
approxarghighaccu}} \right \vert \leq 2^{-113}$.  For $r_\hi$ such
that $\left \vert r_\hi \right \vert \leq 2^{-30}$,
$\epsilon_{\mbox{\tiny approxarghighaccu}}$ is bounded by $\left \vert
\epsilon_{\mbox{\tiny approxarghighaccu}} \right \vert \leq 2^{-160}$.

The polynomial $p\left( r_\hi \right)$ is evaluated as follows:
\begin{enumerate}
\item The high order terms of $p\left( r_\hi \right)$, $c_5 + r_\hi
\cdot \left( c_6 + r_\hi \cdot c_7 \right)$ are evaluated in double
precision using Horner's scheme.  The result of this evaluation is
stored in $highPoly \approx c_5 + r_\hi \cdot \left( c_6 + r_\hi \cdot
c_7 \right)$.
\item The multiplication $r_\hi \cdot highPoly$ is implemented using
an exact operator and yields to a double-double $t_{1\hi} +
t_{1\lo}$. The following steps leading to $t_{4\hi} + t_{4\lo} \approx
\left( c_{3\hi} + c_{3\lo} \right) + r_\hi \cdot \left( \left(
c_{4\hi} + c_{4\lo} \right) + \left( t_{1\hi} + t_{1\lo} \right)
\right)$ are implemented using double-double computations and Horner's
scheme.
\item The sum of the low order terms $r_\hi + \frac{1}{2} \cdot
r_\hi^2$, stored in a non-overlapped triple-double $lowPoly_\hi +
lowPoly_\mi + lowPoly_\lo$, is computed exactly as follows: first
$r_\hi$ is squared exactly using an exact multiplication operator
producing $rhSquare_\hi + rhSquare_\lo = r_\hi \cdot r_\hi$. Since for
arguments $x$ to the exponential function such that $\left \vert x
\right \vert \leq 2^{-55}$ rounding is trivial in all rounding modes,
we can suppose that $\left \vert x \right > 2^{-55}$. In consequence,
since $x$ is a double precision number, the reduced argument $r_\hi$
is either equal to $0$ or greater in magnitude than $2^{-58}$. So both
$rhSquare_\hi$ and $rhSquare_\lo$ are either exactly $0$ or greater in
magnitude than $\left( 2^{-58} \right)^2 \cdot 2^{-53} =
2^{-169}$. They are thus never subnormal.  Therefore the pairwise
multiplication of $rhSquare_\hi + rhSquare_\lo$ by $\frac{1}{2}$
yielding to $rhSquareHalf_\hi + rhSquareHalf_\lo = \frac{1}{2} \cdot
r_\hi^2$ is exact. Since $r_\hi$ is such that $\left \vert r_\hi
\right \vert \leq 2^{-13}$, $r_\hi + rhSquareHalf_\hi +
rhSquareHalf_\lo$ can be considered as a partially overlapped
triple-double number. The overlap bound is such that $\left \vert
rhSquareHalf_\hi \right \vert \leq 2^{-12} \cdot \left \vert r_\hi
\right \vert$ and $\left \vert rhSquareHalf_\lo \right \vert \leq
2^{-53} \cdot \left \vert rhSquareHalf_\hi \right \vert$.  Thus it is
possible to use the \Renormalize~ sequence
\cite{Lauter2005LIP:tripledouble} to obtain a non-overlapped
triple-double $lowPoly_\hi + lowPoly_\mi + lowPoly_\lo$ which is
exactly equal to $r_\hi + \frac{1}{2} \cdot r_\hi^2$ because the
renormalization operator is exact and all preceeding operations have
been, too.
\item An triple-double approximation to $r_\hi^3$, stored in
$rhCube_\hi + rhCube_\mi + rhCube_\lo$ is computed by multiplying
$r_\hi$ by the exact $rhSquare_\hi + rhSquare_\lo$ computed in the
previous step. For this operation the \MulDT~ sequence is used.
\item The approximation of the high order terms of the polynomial,
$t_{4\hi} + t_{4\lo}$ is then multiplied by $rhCube_\hi + rhCube_\mi +
rhCube_\lo$ using a triple-double multiplication operator. The result
of this operation is added to $lowPoly_\hi + lowPoly_\mi +
lowPoly_\lo$ in order to obtain a potentially overlapped triple-double
$p_\hi + p_\mi + p_\lo$ approximating $p\left( r_\hi \right)$.
\end{enumerate}
All this steps are implemented by the following code:
\begin{lstlisting}[caption={Accurate phase polynomial approximation},firstnumber=1]
highPoly = accPolyC5 + rh * (accPolyC6 + rh * accPolyC7);

Mul12(&t1h,&t1l,rh,highPoly);
Add22(&t2h,&t2l,accPolyC4h,accPolyC4l,t1h,t1l);
Mul22(&t3h,&t3l,rh,0,t2h,t2l);
Add22(&t4h,&t4l,accPolyC3h,accPolyC3l,t3h,t3l);

Mul12(&rhSquareh,&rhSquarel,rh,rh);
Mul23(&rhCubeh,&rhCubem,&rhCubel,rh,0,rhSquareh,rhSquarel);

rhSquareHalfh = 0.5 * rhSquareh;
rhSquareHalfl = 0.5 * rhSquarel;  

Renormalize3(&lowPolyh,&lowPolym,&lowPolyl,rh,rhSquareHalfh,rhSquareHalfl);

Mul233(&highPolyMulth,&highPolyMultm,&highPolyMultl,t4h,t4l,rhCubeh,rhCubem,rhCubel);

Add33(&ph,&pm,&pl,lowPolyh,lowPolym,lowPolyl,highPolyMulth,highPolyMultm,highPolyMultl);
\end{lstlisting}
For reconstructing $e^x$ out of the polynomial approximation of
$e^{r_\hi}-1$, $e^{r_\mi}-1$, $e^{r_\lo}-1$ and the table values
$tbl_{1\hi} + tbl_{1\mi} + tbl_{1\lo}$ and $tbl_{2\hi} + tbl_{2\mi} +
tbl_{2\lo}$ the following term must be approximated:
$$e^x \approx 2^M \cdot \left( tbl_{1\hi} + tbl_{1\mi} + tbl_{1\lo}
\right) \cdot \left( tbl_{2\hi} + tbl_{2\mi} + tbl_{2\lo} \right)
\cdot \left( 1 + \left( p_\hi + p_\mi + p_\lo \right) \right) \cdot
\left( 1 + r_\mi \right) \cdot \left( 1 + r_\lo \right)$$ First, the
following approximation is possible $$\left( 1 + \left( p_\hi + p_\mi
+ p_\lo \right) \right) \cdot \left( 1 + r_\mi \right) \cdot \left( 1
+ r_\lo \right) \approx 1 + \left( p_\hi + p_\mi + p_\lo + r_\mi +
r_\lo + \left( r_\mi + r_\lo \right) \cdot \left( p_\hi + p_\mi
\right) \right)$$ First an arithmetical approximation $fullPoly_\hi +
fullPoly_\mi + fullPoly_\lo$ to $p_\hi + p_\mi + p_\lo + r_\mi + r_\lo
+ \left( r_\mi + r_\lo \right) \cdot \left( p_\hi + p_\mi \right)$ is
computed as follows:
\begin{enumerate}
\item By means of an exact, unconditional addition, $p_\hi$ and
$p_\mi$, which may be potentially overlapped because of being the
higher significant parts of an overlapped triple-double, are
renormalized. 
\item They are then multiplied by the non-overlapping $r_\mi +
r_\lo$ using a double-double multiplication operator. The result of
this product is added to $r_\mi + r_\lo$ in double-double
precision. 
\item The result of this addition, $q_\hi + q_\lo$, approximates
thus $r_\mi + r_\lo + \left( r_\mi + r_\lo \right) \cdot \left( p_\hi
+ p_\mi \right)$.
\item The triple-double addition operator \AddDTT~ allows then for adding 
$p_\hi + p_\mi + p_\lo$ to $q_\hi + q_\lo$ resulting in $fullPoly_\hi +
fullPoly_\mi + fullPoly_\lo$.
\end{enumerate}
Then $1$ is added to $fullPoly_\hi + fullPoly_\mi + fullPoly_\lo$ by
the following code sequence:
\begin{lstlisting}[caption={Addition with $1$},firstnumber=1]
Add12(polyAddOneh,t5,1,fullPolyh);
Add12Cond(polyAddOnem,t6,t5,fullPolym);
polyAddOnel = t6 + fullPolyl;
\end{lstlisting}
Since the \Add~ operator is exact, the round-off error of this adding
of $1$ is equal to the round-off error in the last addition
$polyAddOne_\lo = t_6 \oplus fullPoly_\lo$. In absolute value, it is
always less than $2^{-53} \cdot \left \vert t_6 + fullPoly_\lo \right
\vert$. Since $\left \vert r_\hi \right \vert \leq 2^{-12}$, one
checks that $\frac{1}{2} < polyAddOne_\hi < 2$. So the relative error
of this addition with $1$, $\epsilon_{\mbox{\tiny addOne}}$ is in
magnitude less than $2^{-52} \cdot \left \vert t_6 + fullPoly_\lo
\right \vert$. This is particularly important when considering high
critical precision worst cases, see section \ref{sec:expaccuracy},
page \pageref{sec:expaccuracy}.

The result of the polynomial approximation, $$polyWithOne_\hi +
polyWithOne_\mi + polyWithOne_\lo \approx e^{r_\hi} \cdot e^{r_\mi}
\cdot e^{r_\lo}$$ is then multiplied in two steps first by $tbl_{1\hi}
+ tbl_{1\mi} + tbl_{2\lo}$ and then by $tbl_{2\hi} + tbl_{2\mi} +
tbl_{2\lo}$ using each time the triple-double multiplication operator
\MulTT. Remark that these multiplications are exact for arguments
$\left \vert x \right \vert \leq 2^{-14}$ because in this case, $k=0$,
$i_1 = 0$ and $i_2 = 0$ which implies that $tbl_{1\hi} = 1$,
$tbl_{2\hi} = 1$ and $tbl_{i\mi} = 0$ and $tbl_{i\lo} = 0$. In fact
machine multiplications by $1$ are always exact. 

The final product of this multiplications may be overlapped and is
therefore renormalized using the \Renormalize~ sequence. This yields
to the non-overlapped triple-double $polyTbl_\hi + polyTbl_\mi +
polyTbl_\lo$ approximating $\frac{e^x}{2^M}$.

All these steps are implemented by the following code sequence:
\begin{lstlisting}[caption={Accurate phase reconstruction},firstnumber=1]
Add12(phnorm,pmnorm,ph,pm);
Mul22(&rmlMultPh,&rmlMultPl,rm,rl,phnorm,pmnorm);
Add22(&qh,&ql,rm,rl,rmlMultPh,rmlMultPl);

Add233Cond(&fullPolyh,&fullPolym,&fullPolyl,qh,ql,ph,pm,pl);
Add12(polyAddOneh,t5,1,fullPolyh);
Add12Cond(polyAddOnem,t6,t5,fullPolym);
polyAddOnel = t6 + fullPolyl;
Mul33(&polyWithTbl1h,&polyWithTbl1m,&polyWithTbl1l,tbl1h,tbl1m,tbl1l,polyAddOneh,polyAddOnem,polyAddOnel);
Mul33(&polyWithTablesh,&polyWithTablesm,&polyWithTablesl,
	tbl2h,tbl2m,tbl2l,
	polyWithTbl1h,polyWithTbl1m,polyWithTbl1l);

Renormalize3(polyTblh,polyTblm,polyTbll,polyWithTablesh,polyWithTablesm,polyWithTablesl);
\end{lstlisting}

The multiplication of $polyTbl_\hi + polyTbl_\mi + polyTbl_\lo$ by
$2^M$ and the final rounding will be discussed in the next section.

\section{Final rounding}\label{sec:expfinalround}
For both quick and accurate phase, final rounding is simple when the
result cannot be underflowed. In this case, the final multiplication
of $t_1 \cdot t_2 \cdot e^r$ by $2^M$ only affects the exponent of $t_1
\cdot t_2 \cdot e^r$. So the rounding test and the final rounding (in
quick and accurate phase) can be done on $t_1 \cdot t_2 \cdot e^r$
before this value is multiplied by $2^M$. This rounding is a standard
\crlibm~ rounding of respectively a double-double or a
triple-double. Since $M$ might be as great as $M = 1024$ (whilst $t_1
\cdot t_2 \cdot e^r < 1$ in this case, because overflow in the final
result has been filtered out), $2^M$ may not be
representable. Nevertheless it is possible not to representate
$2^M$ explicitely in a variable and to replace the operation by the
following sequence. We suppose that $polyTbl_\hi = \round \left( t_1
\cdot t_2 \cdot e^r + \delta \right)$.
\begin{lstlisting}[caption={Final multiplication by $2^M$},firstnumber=1]
polyTblhdb.d = polyTblh;
polyTblhdb.i[HI] += M << 20;
return polyTblhdb.d;
\end{lstlisting}

If the result might be gradually underflowed but is not completely
underflowed (i.e. not equal to $0$ or $0^+$ depending on the rounding
mode), the quick phase is not used and the accurate phase is launched
in any case. This does not sensibly affect performance. The
triple-double result of the accurate phase, \texttt{polyTblh},
\texttt{polyTblm} and \texttt{polyTbll}, where $polyTbl_\hi +
polyTbl_\mi + polyTbl_\lo \approx t_1 \cdot t_2 \cdot e^r$, is
multiplied by $2^M$ and rounded to double precision as follows:
\begin{itemize}
\item $polyTbl_\hi$ is multiplied by $2^M$ in two steps: $2^M$ is not
representable in double precision but $2^{-1000}$ and $2^{M+1000}$
are. This multiplication generates a subnormal $t_4$, which prevents
us from replacing it by an integer sequence manipulating the exponent
of the numbers involved. We have $t_4 = \round \left( 2^M \cdot
polyTbl_\hi\right) = 2^M polyTbl_\hi + \delta$ with $\left \vert
\delta \right \vert \leq \frac{1}{2} \cdot \mUlp\left( \mbox{\small \it denorm} \right)
= 2^{-1075}$.
\item The obtained value $t_4$ is remultiplied by $2^{-M}$, once again
in $2$ steps. This multiplication produces a normal number and is
therefore exact: $t_6 = 2^{-M} \cdot \round\left( 2^M \cdot
polyTbl_\hi \right) = polyTbl_\hi + 2^{-M} \cdot \delta$.
\item Since $\left \vert M \right \vert \leq 1075$ and $\left \vert
polyTbl_\hi \right \vert \leq 2$, one checks that 
$$\frac{1}{2} \cdot polyTbl_\hi \leq t_6 \leq 2 \cdot polyTbl_\hi$$
is verified. So the arithmetical substraction $t_7 = polyTbl_\hi \ominus t_6$ 
is exact by Sterbenz' lemma and one obtains: 
$$t_7 = 2^{-M} \cdot \left( 2^M \cdot polyTbl_\hi - \round \left( 2^M
\cdot polyTbl_\hi \right) \right)$$
We obtain therefore
$$t_4 + 2^M \cdot \left( t_7 + polyTbl_\mi + polyTbl_\lo \right) = 
2^M \cdot \left( polyTbl_\hi + polyTbl_\mi + polyTbl_\lo \right)$$
Further, since the triple-double number
$polyTbl_\hi + polyTbl_\mi + polyTbl_\lo$ is non-overlapping, we know that
$$t_4 \in \left \lbrace r^-, r, r^+\right \rbrace$$
with $r = \round \left( polyTbl_\hi + polyTbl_\mi + polyTbl_\lo \right)$.
In addition, since the precision of a denormal is maximally $52$ bits and 
that of a normal (like $polyTbl_\hi$) is $53$ bits, $t_7$ is either $0$ or 
greater in magnitude than $polyTbl_\mi + polyTbl_\lo$. If this were not the case, 
the triple-double would overlap. Thus $2^M \cdot \left( t_7 + polyTbl_\mi + polyTbl_\lo \right)$
corresponds to the part of the high accuracy mantissa that is rounded off when 
rounding to the subnormal and if $t_7$ is not zero, it contains at least the first bit that is rounded off.
\end{itemize}
The arithmetical steps mentioned are performed by the following code sequence:
\begin{lstlisting}[caption={Underflowed final multiplication and rounding},firstnumber=1]
/* Final rounding and multiplication with 2^M 

   We first multiply the highest significant byte by 2^M in two steps
	and adjust it then depending on the lower significant parts.

	We cannot multiply directly by 2^M since M is less than -1022.
	We first multiply by 2^(-1000) and then by 2^(M+1000).

*/

t3 = polyTblh * twoPowerM1000;

/* Form now twoPowerM with adjusted M */
twoPowerMdb.i[LO] = 0;
twoPowerMdb.i[HI] = (M + 2023) << 20;


/* Multiply with the rest of M, the result will be denormalized */
t4 = t3 * twoPowerMdb.d;

/* For x86, force the compiler to pass through memory for having the right rounding */

t4db.d = t4;   /* Do not #if-ify this line, we need the copy */
#if defined(CRLIBM_TYPECPU_AMD64) || defined(CRLIBM_TYPECPU_X86) 
t4db2.i[HI] = t4db.i[HI];
t4db2.i[LO] = t4db.i[LO];
t4 = t4db2.d;
#endif

/* Remultiply by 2^(-M) for manipulating the rounding error and the lower significant parts */
M *= -1;
twoPowerMdb.i[LO] = 0;
twoPowerMdb.i[HI] = (M + 23) << 20;
t5 = t4 * twoPowerMdb.d;
t6 = t5 * twoPower1000;
t7 = polyTblh - t6;
\end{lstlisting}
One remarks that on $x86$ platforms, it is necessary to write $t_4$ to
memory and to reread it from there in order to to overcome the inexistence
of pseudosubnormals in the underlying $80$ bit register format.

Depending on the rounding mode, $t_4$ is then adjusted to the correct
rounding of \\$2^M \cdot \left( polyTbl_\hi + polyTbl_\mi + polyTbl_\lo
\right)$ as follows:
\begin{itemize}
\item In round-to-nearest mode, the rounding decision when rounding to
a subnormal is made at a constant value $\frac{1}{2} \cdot \mUlp\left(
\mbox{\small \it denorm}\right) = 2^{-1075}$. 

Rounding is simple for round-to-nearest when the mantissa does not
contain a one following the last mantissa bit of the rounded
result. In this case, the rounding downwards and thus equivalent to a
truncation. Truncation to different lengths is associative. Omitting
$polyTbl_\mi + polyTbl_\lo$ is a truncation. The rounding of $2^M
\cdot polyTbl_\hi$ to a subnormal is correct as per the use of a IEEE
754 operation. So $t_4$ already is equal to $\round\left( polyTbl_\hi
+ polyTbl_\mi + polyTbl_\lo \right)$.

If the first bit following the last mantissa bit of the rounded result
is a one, two cases must be considered: if the TMD's case is such that
the next following mantissa one is contained in the bits of
$polyTbl_\hi$ that are rounded of, the rounding $\round \left( 2^M
\cdot polyTbl_\hi \right)$ is equivalent to the rounding $\round
\left( 2^M \cdot \left( polyTbl_\hi + polyTbl_\mi + polyTbl_\lo
\right) \right)$ because both roundings are upwards. So in this case,
too, $t_4$ already contains the correct result. 

In contrast, if the the TMD's case is such that the next following
mantissa one (after the first one following the rounded mantissa) is
only contained in $polyTbl_\mi + polyTbl_\lo$, the rounding direction
of $\round \left( 2^M \cdot polyTbl_\hi \right)$ and $\round \left(
2^M \cdot \left( polyTbl_\hi + polyTbl_\mi + polyTbl_\lo \right)
\right)$ may be different.  As $t_7$ is the (scaled) correction of the
roundoff of $\round \left( 2^M \cdot polyTbl_\hi \right)$ and greater
in magnitude than $polyTbl_\mi + polyTbl_\lo$, its sign determines the
rounding direction of the rounding $t_4 = \round \left( 2^M \cdot
polyTbl_\hi \right)$. The sign of $polyTbl_\mi = \round \left(
polyTbl_\hi + polyTbl_\lo \right)$ determines then that of the
direction of \\$\round \left( 2^M \cdot \left( polyTbl_\hi + polyTbl_\mi
+ polyTbl_\lo \right) \right)$ and such whether $t_4$ must be adjusted
by $\pm 1 \mUlp$.

The algorithm is thus the following: $2^M \cdot t_7$ is compared to
$\frac{1}{2} \cdot \mUlp\left( \mbox{\small \it denorm}\right)$ by
comparing $t_7$ to $2^{-1075-M}$. This determines whether the rounding
is easy and $t_4$ can be returned or whether an adjustment must be
made. If the latter is the case, the signs of $t_7$ and $polyTbl_\hi$ 
are examined and $t_4$ is adjusted. Since $e^x > 0 \mbox{~~} \forall x \in \R$,
the adjustment of $t_4$ by $\pm \mUlp$ can be simplified.
The code sequence below implements this:
\begin{lstlisting}[caption={Rounding adjustment in round-to-nearest},firstnumber=1]
/* The rounding decision is made at 1/2 ulp of a denormal, i.e. at 2^(-1075)
	We construct this number and by comparing with it we get to know 
	whether we are in a difficult rounding case or not. If not we just return 
	the known result. Otherwise we continue with further tests.
*/

twoPowerMdb.i[LO] = 0;
twoPowerMdb.i[HI] = (M - 52) << 20;

if (ABS(t7) != twoPowerMdb.d) return t4;

/* If we are here, we are in a difficult rounding case */

/* We have to adjust the result iff the sign of the error on 
	rounding 2^M * polyTblh (which must be an ulp of a denormal) 
	and polyTblm +arith polyTbll is the same which means that 
	the error made was greater than an ulp of an denormal.
*/

polyTblm = polyTblm + polyTbll;

if (t7 > 0.0) {
  if (polyTblm > 0.0) {
	 t4db.l++;
	 return t4db.d;
  } else return t4;
} else {
  if (polyTblm < 0.0) {
	 t4db.l--;
	 return t4db.d;
  } else return t4;
}
\end{lstlisting}
\item In round-upwards mode, the rounding~~ $\roundup \left( polyTbl_\hi
+ polyTbl_\mi + polyTbl_\lo \right)$ is determined by $\round\left(
polyTbl_\hi \right)$ and the rounding rest $2^M \cdot \left( t_7 +
polyTbl_\mi + polyTbl_\lo \right)$. 

If $t_7$ not equal to $0$, it is greater in magnitude than
$polyTbl_\mi + polyTbl_\lo$. Thus the rounding direction of the
to-nearest rounding $\round\left( polyTbl_\hi \right)$ is downwards if
$t_7 + polyTbl_\mi + polyTbl_\lo$ is positive. In this case, an
adjustment of $+ 1 \mUlp$ must be made on $t_4$.

If $t_7$ is equal to $0$, the rounding $\round\left( polyTbl_\hi
\right)$ was errorless and $t_4 = 2^M \cdot polyTbl_\hi$. So we get
$$\roundup\left( 2^M \cdot \left( polyTbl_\hi + polyTbl_\mi +
polyTbl_\lo \right) \right) = \roundup\left( t_4 + 2^M \cdot \left(
polyTbl_\mi + polyTbl_\lo \right) \right)$$ Clearly, $2^M \cdot \left(
polyTbl_\mi + polyTbl_\lo \right)$ is less than $\mUlp\left( t_4
\right)$ because $polyTbl_\hi + polyTbl_\mi + polyTbl_\lo$ is
non-overlapping. One can show that
$$\roundup\left( x + \mu \right) = \roundup\left( x + \nu \right)$$ if
$x \in \F$ and $\sgn\left( \mu \right) = \sgn\left( \nu \right)$,
$\left \vert \mu \right \vert, \left \vert \nu \right \vert <
\mUlp\left( x \right)$ and $\mu, \nu \in \R$
\cite{Lauter2005LIP:tripledouble}.  Since the algebraic images of double
arguments have been filtered out, it is thus possible to find $\mu \in \R$ such that
with $\nu = 2^M \cdot \left( polyTbl_\mi + polyTbl_\lo \right)$ respectively 
$\nu = \mUlp\left(t_4\right) + 2^M \cdot \left( polyTbl_\mi + polyTbl_\lo \right)$
the following can be verified:
$$\roundup \left( t_4 + 2^M \cdot \left( polyTbl_\mi + polyTbl_\lo
\right) \right) = \left \lbrace \begin{array}{ll} t_4 & \mbox{ if }
polyTbl_\mi + polyTbl_\lo < 0 \\ t_4^+ & \mbox{ otherwise} \end{array}
\right.$$

So it suffices to add $t_7$ and $polyTbl_\mi = \round\left(
polyTbl_\mi + polyTbl\lo \right)$ together and to check for the sign
of this sum. The rounding error of this operation may not affect the
sign of its result. If the sign is positive, $+1 \mUlp$ is added 
to $t_4$. The following code sequence realizes this:
\begin{lstlisting}[caption={Rounding adjustment in round-upwards},firstnumber=1]
/* The rounding can be decided using the sign of the arithmetical sum of the
	round-to-nearest-error (i.e. t7) and the lower part(s) of the final result.
	We add first the lower parts and add the result to the error in t7. We have to 
	keep in mind that everything is scaled by 2^(-M).
	t8 can never be exactly 0 since we filter out the cases where the image of the 
	function is algebraic and the implementation is exacter than the TMD worst case.
*/

polyTblm = polyTblm + polyTbll;
t8 = t7 + polyTblm;

/* Since we are rounding upwards, the round-to-nearest-rounding result in t4 is 
	equal to the final result if the rounding error (i.e. the error plus the lower parts)
	is negative, i.e. if the rounding-to-nearest was upwards.
*/

if (t8 < 0.0) return t4;

/* If we are here, we must adjust the final result by +1ulp 
	Relying on the fact that the exponential is always positive, we can simplify this
	adjustment 
*/

t4db.l++;
return t4db.d;
\end{lstlisting}
\item Round-downwards mode is analogous to round-upwards mode with signs inverted.
\item Round-towards-zero is equivalent to rounding downwards.
\end{itemize}
\section{Accuracy bounds}\label{sec:expaccuracy}
In this section we give an overview on the error bound
computation. The actual error bound proof is implemented using the
Gappa tool.

An implementation of the exponential function in double precision can
be considered to be correctly rounding if the accuracy of the accurate
phase is at least $113$ bits for arguments $x$ such that $\left \vert
x \right \vert \geq 2^{-30}$ and at least $158$ bits for $2^{-54} \leq
\left \vert x \right \vert < 2^{-30}$ -- provided that the rounding
test after the quick phase is correct \cite{DinDefLau2004LIP}.

In order to give a first error estimate, one can consider
\begin{eqnarray*}
\mbox{\tt exp(x)} & = & 2^M \cdot tbl_1 \cdot tbl_2 \cdot \left( 1 +
p\left( r_\hi \right) \right) \cdot \left( 1 + r_\mi \right) \cdot
\left( 1 + r_\lo \right) \cdot \left( 1 + \epsilon_{\mbox{\tiny
arith}} \right) \\ & = & 2^M \cdot t_1 \cdot \left( 1 +
\epsilon_{\mbox{\tiny tbl1}} \right) \cdot t_2 \left( 1 +
\epsilon_{\mbox{\tiny tbl1}} \right) \cdot \\ & & \cdot \left( 1 +
\left( e^{r_\hi} - 1 \right) \cdot \left( 1 + \epsilon_{\mbox{\tiny
approxhigh}} \right) \right) \cdot \\ & & \cdot \left( 1 + \left(
e^{r_\mi} - 1 \right) \cdot \left( 1 + \epsilon_{\mbox{\tiny
approxmiddle}} \right) \right) \cdot \\ & & \cdot \left( 1 + \left(
e^{r_\lo} - 1 \right) \cdot \left( 1 + \epsilon_{\mbox{\tiny
approxlower}} \right) \right) \cdot \left( 1 + \epsilon_{\mbox{\tiny
arith}} \right) \\ & = & 2^M \cdot t_1 \cdot t_2 \cdot e^{r_\hi +
r_\mi + r_\lo} \cdot \\ & & \cdot \left( 1 + \epsilon_{\mbox{\tiny
tbl1}} \right) \cdot \left( 1 + \epsilon_{\mbox{\tiny tbl2}} \right)
\cdot \left( 1 + \epsilon_{\mbox{\tiny approxhigh}}^\prime \right)
\cdot \left( 1 + \epsilon_{\mbox{\tiny approxmiddle}}^\prime \right)
\cdot \left( 1 + \epsilon_{\mbox{\tiny approxlower}}^\prime \right)
\cdot \left( 1 + \epsilon_{\mbox{\tiny arith}} \right) \\ & = & 2^M
\cdot t_1 \cdot t_2 \cdot e^{\hat{r}} \cdot \\ & & \cdot \left( 1 +
\epsilon_{\mbox{\tiny tbl1}} \right) \cdot \left( 1 +
\epsilon_{\mbox{\tiny tbl2}} \right) \cdot \left( 1 +
\epsilon_{\mbox{\tiny approxhigh}}^\prime \right) \cdot \left( 1 +
\epsilon_{\mbox{\tiny approxmiddle}}^\prime \right) \cdot \left( 1 +
\epsilon_{\mbox{\tiny approxlower}}^\prime \right) \cdot \left( 1 +
\epsilon_{\mbox{\tiny arith}} \right) \cdot \left( 1 +
\epsilon_{\mbox{\tiny argred}} \right) \\ & = & e^x \cdot \left( 1 +
\epsilon \right)
\end{eqnarray*}
where $\epsilon_{\mbox{\tiny approxhigh}}^\prime =
\epsilon_{\mbox{\tiny approxhigh}} - \frac{\epsilon_{\mbox{\tiny
approxhigh}}}{e^{r_\hi}}$, $\epsilon_{\mbox{\tiny
approxmiddle}}^\prime = \epsilon_{\mbox{\tiny approxmiddle}} -
\frac{\epsilon_{\mbox{\tiny approxmiddle}}}{e^{r_\mi}}$ and
$\epsilon_{\mbox{\tiny approxlower}}^\prime = \epsilon_{\mbox{\tiny
approxlower}} - \frac{\epsilon_{\mbox{\tiny
approxlower}}}{e^{r_\lo}}$.  The Gappa proof files integrate all these
errors and allow for evaluating the relative arithmetical round-off
error $\epsilon_{\mbox{\tiny arith}}$.

%TODO: inserer les valeurs obtenues en Gappa pour les deux phases

\section{Timings}\label{sec:exptiming}
For evaluating the timings of the triple-double based implementation
of the exponential function $e^x$, in comparison with other correctly
rounded functions.  ``{\tt crlibm} portable using {\tt scslib}'' still
stands for a logarithm implementation in {\tt crlibm} before the work
on triple-double. The values are given in arbitrary units and obtained
on a IBM Power 5 processor with gcc 3.3.3 on a Linux Kernel 2.6.5. The
timings on other systems are comparable.
\begin{center}
\begin{tabular}{|l|r|r|}
 \hline
  Library                       &     avg time  & max time \\
 \hline
 \hline
 \texttt{MPFR}   &   2128    & 4908        \\ 
 \hline
 \texttt{crlibm} portable using \texttt{scslib}   &   44    & 1976        \\ 
 \hline
 \texttt{crlibm} portable using triple-double      &        39    & 258        \\ 
 \hline
 default \texttt{libm} (IBM's {\tt libultim})  &        34    & 221062      \\ 
 \hline
\end{tabular}
\end{center}
On average, our triple-double based implementation wins about $12\%$
speed-up in comparison with the SCS based implementation. It is
however slightly less performant than Ziv's library.

Concerning worst case timing, the results are more striking and
confirm the general results concering triple-double: the use of
triple-double arithmetic instead of the SCS format allows for a
speed-up of a factor of about $7.65$. In comparison with IBM's {\tt
libultim} a performance gain of a factor $857$ is achieved. The timing
difference between average and worst-case is decreased to a factor of
about $6.6$.

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "crlibm"
%%% End: 

